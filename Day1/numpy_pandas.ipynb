{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy & Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy and Arrays\n",
    "\n",
    "Numpy is a powerful numeric library that is essential for anyone analyzing data with Python. Numpy is a huge package that can support a multitude of tasks. Numpy is also inextricably linked to SciPy, a powerful library for scientific computing with capabilities for fitting, linear algebra, machine learning, etc. Here we are just going to cover some of the basics of numpy, but I encourage you to check out the numpy documentation pages (https://numpy.org/doc/stable/) to get an idea of the variety of things you can do.\n",
    "\n",
    "Arrays are a data type which is fundamental to Numpy. In some ways Numpy arrays are like Python lists:\n",
    "    - both are used for storing data/objects\n",
    "    - both are mutable\n",
    "    - items can be extracted from both using indexing and slicing\n",
    "    - both can be iterated over\n",
    "\n",
    "However there are key aspects of arrays that make them very different:\n",
    "    - most operators act on the elements of an array instead of the array as a whole\n",
    "    - arrays can only hold data of a single type\n",
    "    - arrays can efficiently store large amounts of data in memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create some sample lists\n",
    "xlist = [1, 2, 3, 4]\n",
    "ylist = [1, 4, 9, 16]\n",
    "\n",
    "# create some sample arrays\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array([1, 4, 9, 16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's checkout the different behaviors between lists and arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xlist * 4)\n",
    "\n",
    "print(x * 4)\n",
    "\n",
    "print(x / 4)\n",
    "\n",
    "print(xlist / 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the list was repeated 4 times, whereas each element of the array was multiplied by 4 and the result ended up being the same length.\n",
    "\n",
    "Division works element-wise for arrays, but division is not defined and produces an error when performed on a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating, indexing, and slicing\n",
    "\n",
    "Iterating over a 1D array looks just like iterating over a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in xlist:\n",
    "    print(val)\n",
    "\n",
    "for val in x:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating an N-dimensional array will iterate over slices along the first dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((5, 5))\n",
    "\n",
    "for val in y:\n",
    "    print(val)\n",
    "\n",
    "print()\n",
    "# you could accomplish the same thing like this (but you probably shouldn't)\n",
    "for i in range(y.shape[0]):\n",
    "    val = y[i, :]\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select subsets of the array using conditionals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = x[x < 2]\n",
    "xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Tables\n",
    "\n",
    "Pandas is a powerful data analysis package that provides tools for manipulating tabular data. This is particularly useful in many astronomical applications, such as spectroscopy, and time-series. Data is organized into rows and columns where the columns are named and recalled using arbitrary Python objects (strings are the most convenient). This is in contrast to Numpy arrays where columns can only be accessed using integer indices (however, see record arrays https://docs.scipy.org/doc/numpy-1.10.1/user/basics.rec.html).\n",
    "\n",
    "Sorting, querying, merging, and aggregation are some of the most useful Pandas features, but this tutorial will only scratch the surface. See https://pandas.pydata.org/docs/ for the full documentation.\n",
    "\n",
    "\n",
    "Pandas is most useful for dealing with heterogeneous and/or large datasets, when merging or complex queries are needed, or if you have metadata associated with columns (e.g. strings as labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic units/objects in Pandas are the Series and DataFrame objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lets create a sample Series object\n",
    "x = [1.0, 2.0, 4.4, 4.5, 8.8, 9.1, 8.7, 2.3, 2.4, 3.1, 5.9]\n",
    "s = pd.Series(x)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We populated a Series starting from a list of floating point numbers. Notice that two columns are printed in the output. Every entry in a Series has a corresponding integer index, generally these indices are created automatically. The data type of the series is printed below the Series itself. Series objects can only store data of a single type, but any data type can be stored.\n",
    "\n",
    "A Series is like a single column of data in a table. A DataFrame is the Pandas object that represents a full table. Each column in the table is a Series.\n",
    "\n",
    "There are several ways to construct a Pandas DataFrame, including from Numpy arrays, Python dictionaries, a list of Series objects, reading from a CSV, reading from a URL, etc.\n",
    "\n",
    "Let's first construct a single-column DataFrame from our series `s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(s, columns=['sample'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter has special support for displaying DataFrames, simply typing the variable name of a DataFrame at the end of the cell will present a nicely formatted view of the table.\n",
    "\n",
    "Let's add some more columns to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sample_base'] = df['sample'] // 1\n",
    "df['sample_plus1'] = df['sample'] + 1\n",
    "df['sample_squared'] = df['sample']**2\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can access the values in a column using two different syntax.\n",
    "\n",
    "Now sort by the `sample_squared` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='sample_squared')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the indices were re-ordered as well. The indices retain information about the original ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select subsets of the data using conditionals similar to Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df[df['sample'] <= 4]\n",
    "q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.groupby` method is used to create Pandas `DataFrameGroupBy` object which can be used to calculate statistics within the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups that share a common sample_base field\n",
    "g = df.groupby('sample_base')\n",
    "\n",
    "# count number of rows within each group\n",
    "print(g.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also merge DataFrames together using a common column.\n",
    "\n",
    "Lets create a second DataFrame from the same original list of numbers and calculate the `sample_base` field again. We will also calculate a new column called `sample_sqrt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(x, columns=['sample'])\n",
    "\n",
    "df2['sample_base'] = df2['sample'] // 1\n",
    "df2['sample_sqrt'] = np.sqrt(df2['sample'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add this new column into the original DataFrame by matching up the values on a shared column. In this case we want to match up on the original `sample` column.\n",
    "\n",
    "Sometimes we have multiple DataFrames with one or more overlapping columns and we need to combine into a single DataFrame. This is where merging comes in.\n",
    "\n",
    "Merging is a powerful and complex subject. I frequently find myself here: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html to lookup various functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df, df2, on='sample', suffixes=['_original', '_new'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a column name appears in both DataFrames but is not the column that you are merging on, the strings defined in the `suffixes` argument will be appended to the end of the column names.\n",
    "\n",
    "DataFrames can be written and read from files very easily. Many formats are supported but comma separated values (CSV) is the most commonly used in astronomy. The `read_csv` function can actually read a variety of text file formats by specifying the `delimiter` argument.\n",
    "\n",
    "You can also load a CSV directly from a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('sample.csv')\n",
    "\n",
    "!cat sample.csv\n",
    "\n",
    "from_csv = pd.read_csv('sample.csv', index_col=0)\n",
    "from_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best practices\n",
    "\n",
    "It's almost always better to avoid loops when working with Numpy arrays or Pandas DataFrames. If I'm working on a complicated problem and I'm unsure whether to use a loop or array/DataFrame operations I usually write it up in a loop first so that I can conceptualize the problem a little easier then convert later to remove as many loops as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activites\n",
    "\n",
    "We'll break you into small groups. You will have 25 mins. Work on the following two activities as a group.\n",
    "### Roles:\n",
    "- navigator (person with most recent birthday)\n",
    "- driver (person with farthest away birthday)\n",
    "- moderator\n",
    "\n",
    "### Product:\n",
    "- Activity 1: plot of length vs time for both arrays and lists\n",
    "- Activity 2: saved .csv file\n",
    "\n",
    "## Activity #1 \n",
    "\n",
    "Let's see how much faster it is to work with Numpy arrays over Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# First we'll create a long list\n",
    "length = 10000000  # must be an int\n",
    "x = list(range(length))\n",
    "\n",
    "# now lets loop over all of the elements and add one then divide by two\n",
    "# we will also use the time package to time how long it takes\n",
    "t1 = time.time()\n",
    "for i in range(len(x)):\n",
    "    x[i] = (x[i] + 1) / 2\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"Updated {:d} elements in {:4.3f} seconds.\".format(length, t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Change the length of the list and keep track of how long the calculation takes as a function of that length.\n",
    "\n",
    "1. Plot the time as a function of list length.\n",
    "\n",
    "1. Now construct a Numpy array from the list `x` and perform the same calculation for several different array lengths.\n",
    "\n",
    "1. Plot the calculation time as a function of array length and add this line to the plot created in step #2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity #2\n",
    "\n",
    "Lets load a couple files into a Pandas DataFrame and rearrange and merge them into a single file in a more useful format. `example_data/star_names.json` contains a list star names. The `primary_name` column is the primary ID for the star. For each unique `primary_name` there are many `other_names` associated with it. Each `primary_name`+`other_name` combination is stored in a separate row.\n",
    "\n",
    "1. First load the file `example_data/star_names.json` into a Pandas DataFrame. The file is in JSON format so you might look into the `pandas.read_json` function.\n",
    "\n",
    "1. Group the DataFrame on the `primary_name` column and create a custom aggregation function that takes all of the values in the `other_name` column that have the same `primary_name` and converts them into a single string deliminated with a pipe (`|`).\n",
    "\n",
    "1. Load the `example_data/star_props.csv` file into a separate DataFrame and merge this with the grouped DataFrame from step #2.\n",
    "\n",
    "1. Save the result as a new CSV file. The resulting file should look like `example_data/stars_merged.csv`. You may also load this file into Pandas to see what the final DataFrame should look like before saving to a CSV."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
